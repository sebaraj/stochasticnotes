\documentclass{article}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{parskip}


\usepackage[a4paper, margin=1in]{geometry}

\title{S\&DS 351: Stochastic Processes - Homework 6}
\author{Bryan SebaRaj \\[0.8em] Professor Ilias Zadik}
\date{April 4, 2025}

\begin{document}

\maketitle

\subsection*{Problem 4.6}
\textbf{[Wright-Fisher process]} This is a famous urn model from genetics. An urn contains $d$ balls, some black and some white. (These might represent two forms of a gene. We might ask questions like: as genes are sampled randomly to form successive generations, what is the probability that the “white” gene will take over and completely replace the other form?) Here is a way to form the next “generation.” Sample a ball at random from the urn $d$ times, \textit{with replacement}. We get a new, random set of $d$ balls, containing $0, 1, \ldots, d$ white balls, with various probabilities. Call the resulting sample generation 1. Then we sample in the same way from generation 1 to form generation 2, and so on. Let $X_t$ denote the number of white balls in generation $t$. After many generations, the population will have become “fixed”, that is, it will consist of just one color. Suppose that $X_0 = x_0$, some number between $0$ and $d$.

\begin{enumerate}
    \item[(a)] (2 points) Show that the process $\{X_t\}$ is a martingale.

        \textcolor{blue}{Suppose in generation $t$, the urn contains $X_t =
            x$ white balls (with $0\le x\le d$). To step into generation $t+1$, a ball from the urn 
            is sampled $d$ times with replacement. Thus, each ball in
            generation $t+1$ is white with probability \[ p = \frac{x}{d}. \]
            Therefore, conditioned on $X_t=x$, the number of white balls
            in generation $t+1$, follows a binomial
            distribution \[ X_{t+1}\mid \{X_t=x\} \sim
                \operatorname{Binomial}\left(d, \frac{x}{d}\right) \] Therefore,
                the conditional expectation is \[ \mathbb{E}[X_{t+1}\mid X_t=x]
                    = d\cdot \frac{x}{d} = x \] As this holds for all $x$,
                    \[ \mathbb{E}[X_{t+1}\mid \mathcal{F}_t] = X_t, \]
                where $\mathcal{F}_t$ is the natural filtration. Thus,
            $\{X_t\}$ is a martingale. }


    \item[(b)] (2 points) Prove (and not assume like the Problem 4.6 statement says) that $X_t$ will eventually become fixed, that is, it will consist of one color, with probability 1.

    \textcolor{blue}{
        The state space for $\{X_t\}$, $\{0,1,2,\ldots,d\}$, is observably finite. See that the states $0$ and $d$ are absorbing because once $X_t=0$, i.e. all the balls are black, or $X_t=d$, i.e. all the balls are white, every subsequent generation will remain in that state. \\
For any state $x$ with $0 < x < d$, the probability that all $d$ balls sampled are white is given by
\[
\left(\frac{x}{d}\right)^d > 0
\]
and the probability that all $d$ balls sampled are black is
\[
\left(\frac{d-x}{d}\right)^d > 0
\]
Therefore, from any nonabsorbing state there is a strictly positive probability that the next state will be absorbed into either state $0$ or $d$. \\ 
Moreover, because $\{X_t\}$ is a bounded martingale (since $0\le X_t\le d$ for all $t$), the Martingale Convergence Theorem implies that $X_t$ converges almost surely. Given that the only possible limit values are $0$ and $d$,
\[
\mathbb{P}(X_\infty\in\{0,d\})=1
\]
Thus, the process eventually becomes fixed at state 0 or $s$ with probability 1.
}

    \item[(c)] (3 points) Use the martingale to show that the probability that the population eventually becomes all white is $x_0 / d$.

    \textcolor{blue}{Let $p$ be the probabilty that the population eventually becomes all white, i.e. state $d$. 
\[
p = \mathbb{P}(X_\infty = d)
\]
Since $\{X_t\}$ is a martingale and converges almost surely to $X_\infty$,
\[
\mathbb{E}[X_\infty] = \lim_{t\to\infty}\mathbb{E}[X_t] = x_0
\]
where $x_0$ is the initial number of white balls. \\
Rewriting,
\[
\mathbb{E}[X_\infty] = 0\cdot \mathbb{P}(X_\infty = 0) + d\cdot \mathbb{P}(X_\infty = d) = d\,p.
\]
Thus,
\[
    d\,p = \mathbb{E}[X_\infty]= x_0 
\]
\[
    p = \frac{x_0}{d}
\]
}

\end{enumerate}

\subsection*{Problem 4.10 (3 points)}
[Doob’s inequality for submartingales] Let $X_0, X_1, \ldots$ be a nonnegative submartingale, and let $b$ be a positive number. Prove that
\[
\mathbb{P}(\max(X_0, \ldots, X_n) \geq b) \leq \frac{\mathbb{E}(X_n)}{b},
\]
using the following steps as hints:

\begin{enumerate}
    \item[(a)] Define $\tau$ to be the first time $t$ such that $X_t \geq b$, or $n$, whichever comes first; that is, $\tau = \inf\{t : X_t \geq b\} \wedge n$. Argue that $\{\max(X_0, \ldots, X_n) \geq b\} = \{X_\tau \geq b\}$.

        \textcolor{blue}{Let $\{X_t\}_{t\ge0}$ be a nonnegative submartingale and let $b>0$. Let the stopping time be
\[
\tau = \inf\{t \ge 0 : X_t \ge b\} \wedge n
\]
% We first show that 
% \[
% \left\{\max_{0\le t \le n} X_t \ge b\right\} = \{X_\tau \ge b\}.
% \]
% \textbf{(a)} 
If $\max_{0\le t\le n} X_t \ge b$, then by definition, there exists a time $t \le n$ such that $X_t \ge b$. By the definition of $\tau$, it follows that $\tau \le t$ and $X_\tau \ge b$. Conversely, if $X_\tau \ge b$, then
\[
\max_{0\le t\le n} X_t \ge X_\tau \ge b
\]
Thus, $\{\max(X_0, \ldots, X_n) \geq b\} = \{X_\tau \geq b\}$. }

    \item[(b)] Apply Markov’s inequality, and use an Optional Sampling theorem.

        \textcolor{blue}{By Markov's inequality,
\[
\mathbb{P}(X_\tau \ge b) \le \frac{\mathbb{E}[X_\tau]}{b}
\]
Since $\tau$ is bounded by $n$, the Optional Sampling Theorem applies to the submartingale $\{X_t\}$, yielding
\[
\mathbb{E}[X_\tau] \le \mathbb{E}[X_n]
\]
Therefore, 
\[
\mathbb{P}\left(\max(X_0, \ldots, X_n) \geq b\right) = \mathbb{P}(X_\tau \ge b) \le \frac{\mathbb{E}[X_\tau]}{b} \le \frac{\mathbb{E}[X_n]}{b}
\]}
\end{enumerate}


\subsection*{Problem 4.13 (5 points)}
In Theorem (4.38) there is nothing special about assuming nonnegativity, that is, a lower bound of zero. Show that if $\{X_t\}$ is a supermartingale and there is a random variable $X$ with $\mathbb{E}[|X|] < \infty$ and $X_t \geq X$ for all $t$, then $X_t$ converges with probability 1 as $t \to \infty$.

\textbf{Theorem (4.38)}: A nonnegative supermartingale converges with probability 1.

\textcolor{blue}{Let $\{X_t\}_{t\ge0}$ be a supermartingale. Suppose there exists some random variable $X$ with $\mathbb{E}[|X|] < \infty$ s.t.
\[
X_t \ge X, \quad \forall t \ge 0
\]
Define the process
\[
Y_t = X_t - X, \quad t \ge 0
\]
Since $X_t \ge X$, $Y_t \ge 0$, $\forall t$. Therefore, without assuming nonnegativity in $\{X_t\}$, $\{Y_t\}$ is a nonnegative process. Confirming the supermartingale property for $\{Y_t\}$,
\[
\mathbb{E}[Y_{t+1}\mid \mathcal{F}_t] = \mathbb{E}[X_{t+1} - X \mid \mathcal{F}_t] 
= \mathbb{E}[X_{t+1}\mid \mathcal{F}_t] - X
\]
Since $\{X_t\}$ is a supermartingale,
\[
\mathbb{E}[X_{t+1}\mid \mathcal{F}_t] \le X_t
\]
Thus,
\[
\mathbb{E}[Y_{t+1}\mid \mathcal{F}_t] \le X_t - X = Y_t
\]
Therefore, $\{Y_t\}$ is a nonnegative supermartingale. \\
By Theorem (4.38), every nonnegative supermartingale converges w.p. 1. That is, there exists a random variable $Y_\infty$ such that
\[
Y_t \to Y_\infty \quad \text{almost surely as } t \to \infty
\]
Since
\[
X_t = Y_t + X
\]
it follows that
\[
X_t \to Y_\infty + X \quad \text{almost surely as } t \to \infty
\]
Thus, $\{X_t\}$ converges with probability 1.
}

% \textit{Why?} A sequence of nonnegative numbers $x_0, x_1, \ldots$ has only 3 possible behaviors: (1) it can converge to a finite number, (2) it can converge to $\infty$, or (3) it can “oscillate,” with $\liminf x_t < \limsup x_t$. We want to see that with probability 1, our sample path $X_0(\omega), X_1(\omega), \ldots$ will not exhibit either behavior (2) or behavior (3). Convergence to $\infty$ is ruled out by the supermartingale property. That is, if $X_t \to \infty$ on a set of positive probability, we would have $\mathbb{E}(X_t) \to \infty$. (Note that since the random variables are nonnegative, we cannot have $X_t \to -\infty$ on some other set of positive probability to compensate and keep the expectation bounded). But since $\mathbb{E}(X_t) \leq \mathbb{E}(X_0)$ for all $t$, it cannot be the case that $\mathbb{E}(X_t) \to \infty$. So (2) is ruled out.

% For (3), let $a$ and $b$ be arbitrary nonnegative numbers, with $a < b$, say. We want to see that the path cannot oscillate infinitely many times, being below $a$ infinitely many times and also above $b$ infinitely many times. But we know that whenever the process gets below $a$, the probability that it ever goes above $b$ after that is only $a/b$ at most. So each time the process gets below $a$, there is a probability at least $1 - a/b$ that it will never again attain the level $b$. So with probability 1, eventually the process must stop making “upcrossings” from below $a$ to above $b$, so that with probability 1, the process does not oscillate as in case (3).


\subsection*{Problem 4.16 (10 points)}
Let $\{M_t\}$ be a likelihood ratio martingale as discussed in Example 4.9.

% Example 4.9: Suppose random variables $X_1, X_2, \ldots$ are independent with probability density function $f$, but they are \textit{really} distributed according to the density $g$. For simplicity (to eliminate worries related to dividing by 0) suppose that $\{x : f(x) > 0\} = \{x : g(x) > 0\}$. Define the likelihood ratio process $\{M_t\}$ by $M_0 = 1$ and
% \[
% M_t = \frac{g(X_1)}{f(X_1)} \cdots \frac{g(X_t)}{f(X_t)}.
% \]
%
% Then since $M_{t+1} = M_t \cdot \frac{g(X_{t+1})}{f(X_{t+1})}$, we have:
% \[
% \mathbb{E}(M_{t+1} \mid X_1, \ldots, X_t) = M_t \cdot \int \frac{g(x)}{f(x)} f(x) dx = M_t.
% \]
% So $\{M_t\}$ is a martingale.

\begin{enumerate}
    \item[(a)] Show that $\mathbb{E}M_t = 1$ for all $t$.

    \textcolor{blue}{Suppose $M_0 = 1$ and $\forall t \ge 0$, 
\[
M_{t+1} = M_t \cdot \frac{g(X_{t+1})}{f(X_{t+1})}
\]
Since the random variables $X_1, X_2, \ldots$ are independent and $M_t$ is $\mathcal{F}_t$-measurable, where $\mathcal{F}_t=\sigma(X_1,\ldots,X_t)$,
\[
\mathbb{E}\bigl(M_{t+1}\mid\mathcal{F}_t\bigr) 
= M_t \cdot \int \frac{g(x)}{f(x)}\, f(x) \,dx 
= M_t
\]
Taking expectations on both sides,
\[
\mathbb{E}[M_{t+1}] = \mathbb{E}\bigl(\mathbb{E}(M_{t+1}\mid\mathcal{F}_t)\bigr) = \mathbb{E}[M_t]
\]
Since $\mathbb{E}[M_0]=1$, induction trivially shows that 
$\mathbb{E}[M_t]=1, \quad \forall t\ge0$
}

    \item[(b)] Show that as $t \to \infty$, we have $M_t \to 0$ with probability 1.

    \textcolor{blue}{
        Suppose $g \neq f$, s.t. $\frac{g(x)}{f(x)}$ is not identically equal to 1. See that under the measure corresponding to the density $f$, by Jensen's inequality shows
\[
\mathbb{E}_f\!\left[\log\frac{g(X_1)}{f(X_1)}\right] 
\le \log\mathbb{E}_f\!\left[\frac{g(X_1)}{f(X_1)}\right] 
=\log 1 = 0, \text{ if } g \neq f 
\]
Therefore, $\mu$ can be defined as 
\[
    \mu = \mathbb{E}_f\!\left[\log\frac{g(X_1)}{f(X_1)}\right], \text{ where } \mu < 0
\]
Since $X_1, X_2, \ldots$ are i.i.d. with density $f$, by the Strong Law of Large Numbers,
\[
    \frac{1}{t}\sum_{i=1}^t \log\frac{g(X_i)}{f(X_i)} \to \mu \quad \text{ w.p. 1}
\]
That is,
\[
\frac{1}{t}\log M_t \to \mu < 0 \quad \text{ w.p. 1}
\]
Thus, $\log M_t \to -\infty$ w.p. 1, so
\[
M_t \to 0 \quad \text{ w.p. 1}
\]}

\end{enumerate}


\subsection*{Problem 4.19 (5 points)}
Suppose $T$ is a stopping time and $\{X_t\}$ is a submartingale. Define $Y_t = X_{t \wedge T}$. Show that $\{Y_t\}$ is a submartingale.

\textcolor{blue}{
    Let $\{X_t\}_{t\ge 0}$ be a submartingale w.r.t. the filtration $\{\mathcal{F}_t\}_{t\ge 0}$. Let $T$ be a stopping time. Define the stopped process $\{Y_t\}$ as
\[
Y_t = X_{t\wedge T}, \quad t\ge 0
\]
% We wish to show that $\{Y_t\}$ is a submartingale, i.e., that for all $0\le s < t$,
% \[
% \mathbb{E}\bigl[Y_t \mid \mathcal{F}_s\bigr] \ge Y_s \quad \text{a.s.}
% \]
First fix $0\le s < t$. Consider the event $\{T \le s\}$ and its complement $\{T > s\}$ partition the probability space. \\ 
Case 1: When $\{T\le s\}$,
\[
s\wedge T = T \quad \text{and} \quad t\wedge T = T
\]
As such,
\[
Y_s = X_T \quad \text{and} \quad Y_t = X_T
\]
Thus,
\[
    \mathbb{E}\bigl[Y_t \mid \mathcal{F}_s\bigr] = X_T = Y_s \quad \text{ when } \{T\le s\}
\]
Case 2: When $\{T > s\}$, $s\wedge T = s$ and
\[
t\wedge T =
\begin{cases}
t, & \text{if } T > t \\
T, & \text{if } s < T \le t
\end{cases}
\]
First see that the Optimal Samplying Theorem applies as $t\wedge T$ is bounded by $t$. \\
In either case of $t \wedge T$, the submartingale property of $\{X_t\}$ and the Optional Sampling Theorem can be used to obtain
\[
\mathbb{E}\bigl[X_{t\wedge T}\mid\mathcal{F}_s\bigr] \ge X_s
\]
\[
\mathbb{E}\bigl[Y_t\mid\mathcal{F}_s\bigr] \ge X_s = Y_s \quad \text{when } \{T > s\}
\]
Combining the two original cases,
\[
\mathbb{E}\bigl[Y_t\mid\mathcal{F}_s\bigr] \ge Y_s \quad \text{w.p. 1, } \forall 0\le s < t
\]
Thus, $\{Y_t\}$ is a submartingale.
}

\subsection*{1. (Snell’s Envelope (Optimal Stopping))}

This problem will review the optimal employee (in expected value) selection problem. Suppose that we have $N$ candidates that come in for an interview, one at a time. We can model the fit of every candidate to the position of interest as a stochastic process $X_n \in \mathbb{R}_{\geq 0}$ for $0 \leq n \leq N$ and we assume that we know the joint distribution of the $X_n$.

\textbf{Assumption:} We assume that if we pass on a candidate, we cannot ask them to return.

\textit{Note:} The selection procedure must follow a stopping time because we cannot ``look into the future''. In contrast, if we could ask a candidate to return, then our choice would clearly be to select $\max_{1 \leq n \leq N} X_n$.

Therefore, our goal in this problem is to find which stopping time $T$ maximizes $\mathbb{E}X_T$, i.e., it satisfies that for any other stopping time $S$, $\mathbb{E}X_T \geq \mathbb{E}X_S$.

We will construct a supermartingale called Snell’s envelope $Y_n$ recursively (downwards) as follows:

\[
Y_N = X_N
\]
\[
Y_n = \max(X_n, \mathbb{E}[Y_{n+1} | X_0, \ldots, X_n]), \quad 1 \leq n \leq N-1.
\]

Turns out the optimal stopping time is given by $T = \inf\{n \geq 0 \mid X_n = Y_n\}$. Let’s prove it!

\begin{enumerate}
    \item[(a)] (2 points) Prove that $Y_n \geq X_n$ for all $n$.

        \textcolor{blue}{
\noindent
Using backwards induction, consider the base case at time $N$,
\[
Y_N \;=\; X_N
\]
so $Y_N \geq X_N$ trivially. \\
\noindent
Inductive step: Suppose for some $n+1\le N$, $Y_{n+1}\ge X_{n+1}$. Then by the definition of $Y_n$,
\[
Y_n
\;=\;
\max\bigl(X_n,\;\mathbb{E}[Y_{n+1}\mid X_0,\ldots,X_n]\bigr)
\]
By the definition of a maximum,
\[
Y_n \;\geq\; X_n
\quad\text{and}\quad
Y_n \;\geq\; \mathbb{E}[Y_{n+1}\mid X_0,\ldots,X_n]
\]
Hence $Y_n \ge X_n$ and by induction, $Y_n \geq X_n$, $\forall n$.
}
    
    \item[(b)] (3 points) Prove that $Y_n$, $n \geq 0$ is a supermartingale with respect to $X_n, n \geq 0$.
    
        \textcolor{blue}{
%             To show $(Y_n)$ is a supermartingale, we must check
% \[
% \mathbb{E}[\,Y_{n+1} \;\mid\; X_0,\ldots,X_n\,] \;\le\; Y_n
% \quad
% \text{for each } n.
% \]
From the recursive definition,
\[
Y_n
\;=\;
\max\bigl(X_n,\;\mathbb{E}[\,Y_{n+1}\mid X_0,\ldots,X_n]\bigr)
\;\geq\;
\mathbb{E}\bigl[\,Y_{n+1}\mid X_0,\ldots,X_n\bigr]
\]
Taking the conditional expectation on both sides of $Y_{n+1}$ and noting that $Y_n$ is $\sigma(X_0,\ldots,X_n)$-measurable yields
\[
\mathbb{E}\bigl[Y_{n+1}\mid X_0,\ldots,X_n\bigr]
\;\le\;
Y_n
\]
This is precisely the supermartingale property. 
        }

    \item[(c)] (10 points) Use the proof of the optional stopping theorem for supermartingales to conclude $Y_{n \wedge T}$ is a supermartingale with respect to $X_n, n \geq 0$. Here $n \wedge T := \min\{n, T\}$.

        \textcolor{blue}{
            First note that since $N$ is finite and $X_n \geq 0$, the Optional Stopping Theorem can be applied as its integrability and boundedness conditions are met. 
            Since $(Y_n)_{n=0}^N$ is a supermartingale and $T$ is a stopping time, with respect to the natural filtration generated by $X_0,\ldots,X_n$, the Optional Stopping Theorem 
            ensures that the stopped process $Y_{n \wedge T}$ is also a supermartingale. \\
Concretely, for $n \ge 0$,
\[
\mathbb{E}\bigl[Y_{(n+1)\wedge T} \,\big\vert\, X_0,\ldots,X_n\bigr]
\;\le\;
Y_{n \wedge T}
\]
Thus, $Y_{n\wedge T}$ is a supermartingale with respect to $X_n, n \geq 0$
        }
    
    \item[(d)] (10 points) Improve your argument to show that $Y_{n \wedge T}$ is in fact a \textit{martingale} with respect to $X_n, n \geq 0$.

        \textcolor{blue}{
%             We strengthen the supermartingale property to a martingale property. We must show
% \[
% \mathbb{E}\bigl[Y_{(n+1)\wedge T} \,\big\vert\, X_0,\ldots,X_n\bigr]
% \;=\;
% Y_{n \wedge T}
% \quad
% \text{for each } n.
% \]
Notice by definition,
\[
T \;=\;\inf\{\; n \ge 0 : X_n = Y_n \}
\]
Hence $\forall n < T$, 
$X_n < Y_n$. As such, 
\[
Y_n \;=\;\mathbb{E}[Y_{n+1}\mid X_0,\ldots,X_n]
\]
At such $n<T$, the process can be considered to be in a continuation region where $Y_n = \mathbb{E}[\,Y_{n+1}\mid \mathcal{F}_n]$. Now consider the two cases, where $n < T$ and $n\geq T$. \\ 
If $n < T$, then $n\wedge T = n$. As such,
\[
\mathbb{E}[\,Y_{(n+1)\wedge T}\,\mid X_0,\ldots,X_n]
\;=\;
\mathbb{E}[\,Y_{n+1}\,\mid X_0,\ldots,X_n]
\;=\;
Y_n
\;=\;
Y_{n\wedge T}
\]
Note that the first equality holds as $(n+1)\wedge T = n+1$ on $\{n < T\}$. The second equality follows from $Y_n = \mathbb{E}[\,Y_{n+1}\mid \mathcal{F}_n]$ in the continuation region. \\ 
If $n \ge T$, then $n\wedge T = T$ and $(n+1)\wedge T = T$, both sides are simply $Y_T$. This makes the conditional expectation identity trivial. \\ 
Hence, $\forall n\ge 0$, the martingale property holds.
\[
\mathbb{E}[\,Y_{(n+1)\wedge T}\,\mid X_0,\ldots,X_n]
\;=\;
Y_{n\wedge T}
\]
Thus, $Y_{n\wedge T}$ is a martingale.
        }
    
    \item[(e)] (2 points) Use the above to conclude that $\mathbb{E}X_T = \mathbb{E}Y_0$.

        \textcolor{blue}{
            Given that $(Y_{n\wedge T})$ is a martingale, see that 
\[
\mathbb{E}[Y_{n\wedge T}] 
\;=\;
\mathbb{E}[Y_0] 
\quad
\forall n
\]
Since $T \le N$, as the process length is finite, if $n = N$,
\[
Y_{N\wedge T} \;=\; Y_T
\]
However, by definition of $T$ when $\{T < N\}$, $Y_T = X_T$. Also see that when $T=N$, $Y_T = X_T$. 
\[
Y_{N\wedge T} = Y_T = X_T
\]
As such,
\[
    \mathbb{E}[Y_{N\wedge T}] = \mathbb{E}[Y_T] = \mathbb{E}[X_T]
\]
Hence
\[
\mathbb{E}[X_T]
\;=\;
\mathbb{E}[Y_0]
\]
        }
    
    \item[(f)] (3 points) Suppose that we are given an alternative stopping rule $S$. Prove that $\mathbb{E}Y_S \geq \mathbb{E}X_S$.

    \textcolor{blue}{
        Recall from part (a) that $Y_n \ge X_n$ for every $n$. It follows for any stopping time $S$ that
\[
Y_S \;\ge\; X_S
\quad
\text{pointwise}
\]
Note that taking expectations of both sides will preserve the inequality. As such, 
\[
\mathbb{E}[Y_S]
\;\ge\;
\mathbb{E}[X_S]
\]
    }
    
    \item[(g)] (10 points) Now prove that $\mathbb{E}Y_S \leq \mathbb{E}Y_0$. Put the pieces together to prove that $\mathbb{E}X_T \geq \mathbb{E}X_S$.

        \textcolor{blue}{
            Since $(Y_n)$ is a supermartingale, for the stopped process $(Y_{n\wedge S})$, the Optional Stopping Theorem implies that 
\[
\mathbb{E}[\,Y_{n\wedge S}\,] \;\le\; \mathbb{E}[\,Y_0\,],
\quad
\forall n
\]
Note that by choosing $n=N$, which exceeds or meets all possible values of $S$,
\[
\mathbb{E}[\,Y_S\,]
\;\le\;
\mathbb{E}[\,Y_0\,]
\]
Combining with the results from part (f), 
\[
\mathbb{E}[\,X_S\,] \;\le\; \mathbb{E}[\,Y_S\,] \;\le\; \mathbb{E}[\,Y_0\,] \;=\; \mathbb{E}[\,X_T\,]
\]
Thus,
\[
\mathbb{E}[X_T]
\;\ge\;
\mathbb{E}[X_S]
\]
        }
    
    \item[(h)] (Bonus, 5 points) Can you intuitively explain why $T$ is the optimal stopping time?

    \textit{Note:} there is no ``correct'' answer to this, but curious to read your thoughts.

    \textcolor{blue}{ 
        The time $T$ is defined as the first time $X_n$
        meets or exceeds the continuation value, $\mathbb{E}[Y_{n+1}\mid
        \mathcal{F}_n]$. Note that this continuation value is the expected payoff
        if we choose not to stop now. Therefore, if $X_n$ is already
        larger than the expected value of continuing, we should stop
        immediately. Conversely, if the current $X_n$ is smaller than that
        future expectation, we gain in expectation by waiting, i.e. not stopping. This should yield
        the best tradeoff between stopping now and continuing, hence
        yields the best expected payoff among all stopping rules. }

    \item[(i)] Suppose that the data $X_n, n \geq 0$ are drawn uniformly from $[0, 1]$ and are i.i.d.
    \begin{enumerate}
        \item[(i)] (2 points) What is $\mathbb{E}Y_0$ for $N = 2$?

        \textcolor{blue}{
\noindent
Note the three random variables $X_0, X_1, X_2$, each uniform$[0,1]$. By definition,
\[
Y_2 = X_2,
\quad
Y_1 = \max\bigl(X_1,\; \mathbb{E}[Y_2 \mid X_1]\bigr)
     = \max\bigl(X_1,\; \mathbb{E}[X_2]\bigr)
     = \max\bigl(X_1,\; 1/2\bigr)
\]
\[
Y_0 
\;=\; 
\max\bigl(X_0,\; \mathbb{E}[\,Y_1 \mid X_0]\bigr)
\;=\;
\max\bigl(X_0,\; \mathbb{E}[\,Y_1\,]\bigr)
\]
since $Y_1$ is also independent of $X_0$. 
Solving for $\mathbb{E}[Y_1]$,
\[
Y_1 = \max(X_1,\,1/2)
\]
\[
\mathbb{E}[\,Y_1\,]
\;=\;
\int_0^1 \max(x,\,1/2)\,dx
\;=\;
\int_{0}^{1/2} \tfrac12\,dx \;+\;\int_{1/2}^{1} x\,dx
\;=\;
\tfrac12 \cdot \tfrac12 \;+\;\bigl[\tfrac{x^2}{2}\bigr]_{1/2}^1
\;=\;
\tfrac{1}{4} \;+\;\Bigl(\tfrac12 - \tfrac{1}{8}\Bigr)
\;=\;
\tfrac{5}{8}
\]
Therefore
\[
Y_0 = \max\bigl(X_0,\; 5/8\bigr)
\]
\[
\mathbb{E}[\,Y_0\,]
\;=\;
\int_0^1 \max\bigl(x,\,5/8\bigr)\,dx
\;=\;
\int_0^{5/8} \tfrac{5}{8}\,dx
\;+\;
\int_{5/8}^{1} x\,dx
\;=\;
\tfrac{5}{8}\cdot \tfrac{5}{8}
\;+\;
\tfrac{x^2}{2}\Bigr|_{5/8}^1
\]
% First part: $5/8 \times 5/8 = 25/64$. Second part:
% \[
% \Bigl[\tfrac{x^2}{2}\Bigr]_{5/8}^1
% \;=\;
% \tfrac12 - \tfrac{(5/8)^2}{2}
% \;=\;
% \tfrac12 - \tfrac{25}{64}\cdot\tfrac12
% \;=\;
% \tfrac12 - \tfrac{25}{128}
% \;=\;
% \tfrac{64}{128} - \tfrac{25}{128}
% \;=\;
% \tfrac{39}{128}.
% \]
Hence
\[
\mathbb{E}[\,Y_0\,]
\;=\;
\tfrac{25}{64} + \tfrac{39}{128}
\;=\;
\tfrac{50}{128} + \tfrac{39}{128}
\;=\;
\tfrac{89}{128}
\]
Thus for $N=2$, $\mathbb{E}[\,Y_0\,] = 89/128$.
        }

        \item[(ii)] (3 points) What about $N = 3$?

        \textcolor{blue}{
         First note the 4 variables, $X_0, X_1, X_2, X_3$
\[
Y_3 = X_3,\quad
Y_2 = \max\bigl(X_2,\;1/2\bigr)
\]
\[
Y_1
= \max\bigl(X_1,\;\mathbb{E}[\,Y_2\,]\bigr)
= \max\bigl(X_1,\;\mathbb{E}[\max(X_2,1/2)]\bigr)
\]
Using the pre-computed values,
\[
\mathbb{E}[\max(X_2,1/2)]
= \frac{5}{8}
\]
Hence 
\[
Y_1 = \max\bigl(X_1,\,5/8\bigr)
\]
\[
Y_0 = \max\bigl(X_0,\;\mathbb{E}[Y_1]\bigr)
= \max\bigl(X_0,\;\mathbb{E}[\max(X_1,5/8)]\bigr)
\]
\[
\mathbb{E}\bigl[\max(X_1,5/8)\bigr]
= \int_0^1 \max(x,5/8)\,dx
= \frac{5}{8}\cdot\frac{5}{8} + \int_{5/8}^1 x\,dx
= \frac{25}{64} + \left(\frac{1}{2} - \frac{25}{128}\right)
= \frac{25}{64} + \frac{39}{128}
= \frac{89}{128}
\]
Therefore,
\[
Y_0 = \max\bigl(X_0,\; 89/128\bigr)
\]
\[
\mathbb{E}[Y_0]
= \int_0^1 \max\bigl(x,\,89/128\bigr)\,dx
= \int_0^{89/128} \frac{89}{128}\,dx + \int_{89/128}^1 x\,dx
= \frac{89}{128}\cdot\frac{89}{128} 
  + \frac{x^2}{2}\big|_{89/128}^1
\]
% The first part is 
% \(\frac{89}{128}\times \frac{89}{128} = \frac{7921}{16384}.\)
% For the second part,
% \[
% \left[\tfrac{x^2}{2}\right]_{89/128}^1
% = \tfrac12 - \tfrac{(89/128)^2}{2}
% = \tfrac12 - \tfrac{7921}{16384}\cdot \tfrac12
% = \tfrac12 - \tfrac{7921}{32768}
% = \frac{16384}{32768} - \frac{7921}{32768}
% = \frac{8463}{32768}.
% \]
Therefore,
\[
\mathbb{E}[Y_0]
= \frac{7921}{16384} \;+\; \frac{8463}{32768}
= \frac{15842}{32768} \;+\; \frac{8463}{32768}
= \frac{24305}{32768}
\]
So for $N=3$, $\mathbb{E}[Y_0] = 24305/32768 \approx 0.742.$
        }

    \end{enumerate}
\end{enumerate}

\subsection*{2. (The “ABRACADABRA” problem)}

A monkey is sitting next to a typewriter. We assume that the typewriter has exactly 26 keys corresponding to the 26 letters of the English alphabet.

We also assume the following action is taking place: at each time the monkey hits one out of the 26 keys chosen with equal probability and independently from everything else.

\begin{enumerate}
    \item[(a)] (2 points) Prove that the expected number of hits until the letter A is typed is 26.

        \textcolor{blue}{
            Let $T = \min\{\,n \ge 1:\, \text{the }n\text{-th letter that is typed is }A\}$. This makes $T$ a geometric random variable with success probability $p=\tfrac{1}{26}$. As such,
\[
\mathbb{P}(T > n) \;=\; \left(\frac{25}{26}\right)^n
\quad \text{and} \quad
\mathbb{P}(T=n) \;=\; \frac{1}{26}
\left(\frac{25}{26}\right)^{n-1}\,\]
Note that the expectation of such a geometric random variable is
\[
\mathbb{E}[T] \;=\; \frac{1}{p} 
\;=\; 26
\]
Thus the expected number of keystrokes to see the first A is 26.
        }
    
    \item[(b)] Now let’s prove part (a) with martingale theory. Let us assume that a gambling game takes place at a casino based on the keys the monkey hits.
    
    \textbf{Gambling game:} Before each new hit of a key from the monkey, \textit{a new gambler} appears and bets one dollar that the key the monkey is about to hit is going to be the letter A. If the monkey hits A the casino pays 26 dollars to the gambler, otherwise the gambler leaves the game and the casino wins the gambler’s one dollar.
    \begin{itemize}
        \item (3 points) Prove that the ``game is fair'', i.e., the total budget of the casino before every new hit is a martingale.

    \textcolor{blue}{
        Let $M_n$ be the total budget of the casino prior to the $n$-th keystroke. As such, $M_0=0$. Just before the $n$-th letter appears,
        the new gambler pays \$1, so the casino's budget increases by 1.
Then, when the $n$-th letter is realized, there are two scenarios:
if it is A, the casino pays \$26 back, for a net  -25, relative to +1.
If it is not A, the gambler loses \$1, and the casino keeps the \$1.
Hence the change from $M_{n-1}$ to $M_n$ is
\[
M_n - M_{n-1} \;=\;
\begin{cases}
-25, & \text{w.p. } 1/26\\
+1, & \text{w.p. } 25/26
\end{cases}
\]
Therefore,
\[
\mathbb{E}[\,M_n - M_{n-1}\,\mid M_{n-1},\dots]
\;=\;
\frac{1}{26}\times(-25) \;+\; \frac{25}{26}\times (+1)
\;=\; 0
\]
As such,
\[
\mathbb{E}[\,M_n \,\mid\, M_{n-1},\ldots]\;=\;M_{n-1}
\]
Therefore, this game is fair as it is a discrete-time martingale with respect to its natural filtration.
% This means $(M_n)_{n\ge0}$ is indeed a (discrete-time) martingale with respect to its natural filtration.
    }

        \item (5 points) Provide an alternative proof of part (a) using the Optional Stopping Theorem.

    \textcolor{blue}{ 
        Let $T$ be the first time that the letter A appears. By
        its definition, $T$ is a stopping time with respect to $(M_n)$. Since 
        $M_n$ is bounded below as $M_n\ge -25n$, and $T$ cannot exceed
        the time we first see A
        we can apply the Optional
        Stopping Theorem (OST) safely under standard conditions for nonnegative
        or bounded increments. \\
\noindent
First, observe that up to time $T$, i.e. the first A, we have had exactly $T$ gamblers, each paying \$1, so the casino collects \$\(T\). But at time $T$, the letter is A, and the gambler at time $T$ wins \$26, so the casino must pay \$26 to that gambler. As such, the net is now 
\[
M_T \;=\; \underbrace{(+1) + \cdots + (+1)}_{T\text{ times}} \;-\; 26
\;=\;
T \;-\; 26
\]
Since $M_n$ is a martingale and $T$ a bounded stopping time, and a geometric series implies finite expectation, we can apply the OST, 
\[
\mathbb{E}[\,M_T\,] \;=\;\mathbb{E}[\,M_0\,]
\;=\;0
\]
Hence,
\[
\mathbb{E}[\,T - 26\,] \;=\; 0
\]
Therefore,
\[
\mathbb{E}[\,T\,] \;=\; 26
\]
Thus, the expected number of keystrokes before the letter A appears is 26, matching the direct calculation in part (a).
    }

    \end{itemize}
    
    \item[(c)] (15 points) You may be thinking that part (b) is a very complicated way to prove part (a) which is simple. That is true, but this proof idea is in fact very clever and can give other much harder results, like the following.

    Build upon the proof technique of part (b), and prove that the expected number of hits until the monkey types \texttt{ABRACADABRA} is $26^{11} + 26^4 + 26$.

    \textcolor{blue}{
%         Define a process $(M_n)$, the casino's capital at time $n$, that places side-bets on whether the next typed letters complete any partial progress toward \texttt{ABRACADABRA}. Each time we transition from one ``partial match state'' to another, an appropriate net amount is paid in or out so that the increments of $M_n$ have zero expectation. The process is carefully designed so that once \texttt{ABRACADABRA} first appears, $M_\tau$ can be expressed (almost surely) in a way that reveals $\tau$ in the formula. The OST then concludes with the desired $\mathbb{E}[\tau]$.
% \bigskip
% Step 1: Label the prefix-matching states. \\
Define the states $s=0,1,2,\ldots,10$ to represent the number of initial letters of \texttt{ABRACADABRA} that have been matched so far. 
\[
\text{\tt ABRACADABRA} = 
\text{\tt A (0) B (1) R (2) A (3) C (4) A (5) D (6) A (7) B (8) R (9) A (10)}
\]
So when $s=0$, 0 letters are currently matched, i.e. (no partial match), when $s=1$, the recent letter typed was \texttt{A}, matching 1 letter of the pattern so far, etc. \\
Note that \texttt{ABRACADABRA} has a prefix \texttt{ABRA} that is also a suffix of that word. 
% In effect:
% \[
% \underbrace{\text{\tt ABRACADABRA}}_{\text{length 11}}
% \quad\text{ has suffix \texttt{ABRA} of length 4 (and that suffix is also the first 4 letters).}
% \]
Hence if we are in state $s=10$ (i.e., we have matched \texttt{ABRACADABR}),
and the next letter typed is \texttt{A}, then we enter the success state $s=11$
(matching the entire word \texttt{ABRACADABRA} for the first
time). But if the next letter typed is \texttt{B}
then we jump to a state that reflects how many
letters of \texttt{ABRACADABRA} (from the beginning) are matched by the
overlap. For \texttt{ABRACADABR} + \texttt{B}, the new state is $s=2$. \\
% There is a systematic way to define
% these transitions for each possible letter from any state $s$. We won't write
% out all transitions in detail here, but only highlight that:
% \[
% \text{Next letter typed} 
% \quad\longmapsto\quad
% \text{(jump to new state reflecting the new overlap).} 
% \]
% Step 3: Define the casino's payoff structure / side-bets. \\
In order to define the casino's payoff structure, we construct $M_n$, representing the casino's profit at time $n$, by the following \\
\begin{itemize}
\item At every step $n$, depending on the current state $s_n \in \{0,1,\dots,10\}$ and the letter typed, the casino either wins or loses a defined amount such that
  \[
  \mathbb{E}[\Delta M_n \mid \text{previous info}] = 0
  \]
\item Concretely, from each state $s$, if the next letter is the correct letter to advance to $s+1$, a certain payoff is made to the gambler. Otherwise, the gambler pays the casino. The size of the bets is chosen so that each step is a fair bet from the viewpoint of the casino.  \\
\end{itemize}
% One explicit (though slightly tedious) construction is:
\[
\text{At each step, a new gambler invests an amount }X_{s}\text{ if in state }s.
\]
If the typed letter transitions $s$ to $t$, the gambler is paid $X_{t}$ and leaves. Therefore, the net effect on the casino is
\[
\Delta M = - X_{t} + X_{s}
\]
With a goal of 
\(\mathbb{E}[\Delta M \mid s] = 0\),
\[
X_{s} \;=\; \sum_{\ell= \text{all letters}} \Bigl[\tfrac{1}{26} \bigl(-X_{\text{nextState}(s,\ell)} + X_s\bigr)\Bigr]
\]
Solving this system and specifying boundary conditions $X_{11}=0$ as the absorbing success state, yields
\[
\{X_0, X_1,\dots, X_{10}, X_{11}=0\}
\]
% (Here $X_{11}=0$ because once the pattern is fully matched, that gambler’s bet is over.) \\
This yields the results:
\[
X_0 \;=\; 26^{11} + 26^{4} + 26,
\quad
X_4 \;=\; 26^4 + 26,
\quad
X_{10} \;=\; 26,
\quad
X_{11}=0,
\quad
\text{and similarly for the other }X_s.
\]
where the powers $26^{11}, 26^4, 26$ directly reflect how partial overlaps restart the pattern matching. \\
\bigskip
Since, $M_n$ is a martingale, we can solve for $\tau$. \\
Thus $M_n$ is built so that each jump 
\(\Delta M_n = M_n - M_{n-1}\) 
has zero conditional expectation given the state $s_{n-1}$. Hence $(M_n)$ is a martingale. Let $\tau$ be the time we first reach state $s=11$. By the Optional Stopping Theorem,
\[
\mathbb{E}[\,M_{\tau}\,] 
\;=\; \mathbb{E}[\,M_0\,]
\]
But $M_0 = X_0$ since we start in state $s=0$ with that gambler's stake, i.e.\ $M_0 = X_0 = 26^{11} + 26^4 + 26.$ \\
Meanwhile, once $\tau$ is reached, the gambler in state 10 receives $X_{11}=0$ but had invested $X_{10}=26$. So the net effect for the casino from that final transition is $-X_{11}+X_{10}=+26$ minus any prior partial reimbursements. Collecting all partial contributions,
\[
M_{\tau} \;=\; \tau - (26^{11} + 26^4 + 26)
\]
% (a direct analogy to the single-letter case). 
More precisely, when summed across all steps from $1$ to $\tau$, gamblers have collectively contributed $\tau$ dollars into the casino. 
At times when the pattern partially matches, the casino pays out intermediate amounts, culminating in a final payoff at time $\tau$ that ensures the gambler in state 10 is compensated. \\
% A more direct or carefully enumerated argument obtains
As such,
\[
M_{\tau} 
= 
\tau \;-\; \bigl(X_0 - X_{11}\bigr)
= 
\tau \;-\; \bigl(\,(26^{11} + 26^4 + 26) - 0\bigr)
\]
Hence
\[
M_{\tau}
\;=\;
\tau - \bigl(26^{11} + 26^4 + 26\bigr)
\]
Using $\mathbb{E}[\,M_{\tau}\,] = M_0 = 26^{11}+26^4+26$,
\[
\mathbb{E}\Bigl[\tau - \bigl(26^{11} + 26^4 + 26\bigr)\Bigr]
\;=\;
26^{11} + 26^4 + 26
\]
which yields 
\[
\mathbb{E}[\tau]
\;=\;
(26^{11} + 26^4 + 26) \;+\; (26^{11} + 26^4 + 26)
\;-\; 0
\;=\;
26^{11} + 26^4 + 26
\]
Therefore the expected number of hits to see the entire \texttt{ABRACADABRA} is 
$26^{11} + 26^4 + 26$.
    }

\end{enumerate}

\end{document}
