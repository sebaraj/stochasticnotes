\documentclass{article}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{parskip}


\usepackage[a4paper, margin=1in]{geometry}

\title{S\&DS 351: Stochastic Processes - Homework 3}
\author{Bryan SebaRaj \\[0.8em] Professor Ilias Zadik}
\date{February 7, 2025}

\begin{document}

\maketitle

\subsection*{Problem 1} (10 points) Is it possible for a transient state to be periodic? If so, construct an example of such a Markov chain; otherwise, give a mathematical proof why not.

\textcolor{blue}{Note: I (fortunately) solved this after proving problem 3, so for a more thorough proof on how this example is transient, please see Problem 3. \\ \\ 
Yes, it is possible for a transient state to be periodic. Consider a 1-dimensional asymmetric random walk on $\mathbb{Z}$:
\[
   X_{n} \;=\; X_{n-1} \;+\; Z_n,
   \quad\text{where}\quad
   \mathbb{P}(Z_n = +1) \;=\; p
   \quad\text{and}\quad
   \mathbb{P}(Z_n = -1) \;=\; 1 - p,
\]
for some $p \in (0,1)$ with $p \neq \tfrac{1}{2}$. Starting at state 0, state 0 is transient (see Problem 3). \\ \\ 
% We claim that in this Markov chain:
% \begin{enumerate}
%   \item \emph{State 0 is transient} whenever $p \neq \tfrac{1}{2}.$
%   \item \emph{State 0 has period 2}, regardless of $p$ (as long as $p>0$ and $1-p>0$).
% \end{enumerate}
\smallskip
\noindent
Define the period as $d_i = \text{gcd}\{n:P^n(i,i)>0\}$, where $P$ is the transition matrix. \\
In the random walk, the walk must trivially take as many $+1$ steps as $-1$ steps to reach the initial state. Thus one can only return to state $x$ starting from $x$ in an even number of steps. Note that this holds for all integers. Hence for each integer $x$, 
\[
  (P^n)(x,x) \;>\;0 
  \quad\Longrightarrow\quad 
  n \ \text{is even}.
\]
\[
  (P^n)(x,x) \;=\;0 
  \quad\Longrightarrow\quad 
  n \ \text{is odd}.
\]
Therefore, the greatest common divisor of all such $n$ is $2$, and every state $x\in\mathbb{Z}$ has period~$2$.
}
   
\subsection*{Problem 2} Let $X_0, X_1, \dots$ be a Markov chain with transition matrix $P$. Let $k \geq 1$ be an integer.
\begin{enumerate}
    \item[(a)] (5 points) Prove that $Y_n = X_{kn}$ is also a Markov chain. Find its transition matrix.

            \textcolor{blue}{
                Since $Y_n = X_{kn}$, the conditional probability for $Y_{n+1}$ can be defined as
\[
\mathbb{P}\left(X_{k(n+1)} = y_{n+1} \mid X_{kn} = y_n, X_{k(n-1)} = y_{n-1}, \dots, X_0 = y_0\right)
\]
Because $\{X_n\}$ is a Markov chain, it satisfies the Markov property,
 \[
P\bigl(X_{m+1} = x_{m+1} \,\big\vert\, X_m = x_m, \dots, X_0 = x_0\bigr)
= P\bigl(X_{m+1} = x_{m+1} \,\big\vert\, X_m = x_m\bigr).
\]
Applying for the $k$-steps from time $kn$ to time $k(n+1)$,
\[
\mathbb{P}\left(X_{k(n+1)} = y_{n+1} \mid X_{kn} = y_n, X_{k(n-1)} = y_{n-1}, \dots, X_0 = y_0\right)
= \mathbb{P}\left(X_{k(n+1)} = y_{n+1} \mid X_{kn} = y_n\right)
\]
Therefore,
\[
\mathbb{P}\left(Y_{n+1} = y_{n+1} \mid Y_n = y_n, Y_{n-1} = y_{n-1}, \dots, Y_0 = y_0\right)
= \mathbb{P}\left(Y_{n+1} = y_{n+1} \mid Y_n = y_n\right)
\]
Thus, $\{Y_n\}$ satisfies the Markov property and is a Markov chain. \\ \\ 
Solving for the transition matrix, note that for any state $i,j \in S$,
\[
\mathbb{P}(Y_{n+1} = j \mid Y_n = i) = \mathbb{P}(X_{k(n+1)} = j \mid X_{kn} = i)
\]
In the Markov chain $\{X_n\}$, 
\[
\mathbb{P}(X_{k(n+1)} = j \mid X_{kn} = i) = (P^k)_{ij}
\]
Thus, the one-step transition probability for $\{Y_n\}$ is
\[
\mathbb{P}(Y_{n+1} = j \mid Y_n = i) = (P^k)_{ij}.
\]
Therefore, the transition matrix for $\{Y_n\}$ is $P^k$.
% By the definition $Y_n = X_{kn}$,
% \[
% P\bigl(Y_{n+1} = j \,\big\vert\, Y_0 = i_0, \dots, Y_n = i_n\bigr)
% = P\bigl(X_{k(n+1)} = j \,\big\vert\, X_{0} = i_0, X_k = i_1, \dots, X_{kn} = i_n\bigr).
% \]
% Since $\{X_n\}$ is a Markov chain, it satisfies the Markov property:
% \[
% P\bigl(X_{m+1} = x_{m+1} \,\big\vert\, X_0 = x_0, \dots, X_m = x_m\bigr)
% = P\bigl(X_{m+1} = x_{m+1} \,\big\vert\, X_m = x_m\bigr).
% \]
% Applying this property step-by-step for the transitions from time $kn$ to time $k(n+1)$ (i.e., $k$ steps), we obtain:
% \[
% P\bigl(X_{k(n+1)} = j \,\big\vert\, X_{kn} = i_n\bigr) = \bigl(P^k\bigr)(i_n, j).
% \]
% Because all intermediate states between $X_{kn}$ and $X_{k(n+1)}$ do not affect this probability beyond the conditioning on $X_{kn}$, we conclude:
% \[
% P\bigl(X_{k(n+1)} = j \,\big\vert\, X_{0} = i_0, \dots, X_{kn} = i_n\bigr)
% = P\bigl(X_{k(n+1)} = j \,\big\vert\, X_{kn} = i_n\bigr)
% = \bigl(P^k\bigr)(i_n, j).
% \]
% Hence,
% \[
% P\bigl(Y_{n+1} = j \,\big\vert\, Y_0 = i_0, \dots, Y_n = i_n\bigr)
% = P\bigl(Y_{n+1} = j \,\big\vert\, Y_n = i_n\bigr),
% \]
% proving that $\{Y_n\}$ is a Markov chain. \\ \\
% Finally, by the computation above, the one-step transition probability for $Y_n$ from state $i_n$ to state $j$ is exactly $\bigl(P^k\bigr)(i_n, j)$. Therefore, the transition matrix of $\{Y_n\}$ is $P^k$.
}

        
        \item[(b)] (10 points) Suppose that the original chain $\{X_n\}$ is irreducible. Is $\{Y_n\}$ irreducible? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{
            Consider a Markov chain, with state space $S=\{X_0, X_1\}$. Define its transition matrix as $$P_X=
  \left( {\begin{array}{cc}
   0 & 1 \\
   1 & 0 \\
  \end{array} } \right)$$
  Since $X_0$ and $X_1$ communicate, this chain is trivially irreducible. \\ \\ 
  Suppose $k=2$. The transition matrix of $Y_m=X_{2n}$ is $$P_Y=P_X^2=\left( {\begin{array}{cc}
   1 & 0 \\
   0 & 1 \\
  \end{array} } \right)$$
  $X_0$ and $X_1$ do not communicate in the new chain, as $X_0$ and $X_1$ are closed subsets on $S$. Therefore, $Y_n$ is not irreducible. \\ \\ 
  Note that this can be generalized to any Markov chain $X_0, X_1,...,X_k$, where $\mathbb{P}_X(i,j)=1$ for $j = (i + 1) \text{ mod } k$ and $\mathbb{P}_X(i,j)=0$ for all other $i$, for all $j$. This chain is trivially irreducible, and yields a transition matrix $P^k$ which is a $k\times k$ identity matrix. As such, the chain $Y_n$ is not irreducible, as the states $X_0, X_1,...,X_k$ are closed subsets on $S$.
               }

        
        \item[(c)] (10 points) Suppose that the original chain $\{X_n\}$ is aperiodic. Is $\{Y_n\}$ aperiodic? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{\begin{itemize}
\item A Markov chain with transition matrix $P$ is called \emph{aperiodic} if every state $i$ has period~$1$.  Concretely, the period of a state~$i$ is defined as
\[
   d(i) \;=\; \gcd\!\Bigl\{\, n \ge 1 : (P^n)_{ii} > 0 \Bigr\}.
\]
If this $\gcd$ equals~$1$ for every $i$, then the chain is aperiodic.  
\item In the chain $\{Y_n\}$ defined by $Y_n := X_{kn}$, its transition probabilities arise from the $k$-step transition probabilities of the original chain.  In particular,
\[
  \mathbb{P}(Y_{m+1} = j \mid Y_m = i)
  \;=\; \mathbb{P}(X_{k(m+1)} = j \mid X_{km} = i)
  \;=\; \bigl(P^k\bigr)_{ij}.
\]
Hence the transition matrix of $\{Y_n\}$ is exactly $P^k$, and the $m$-step transition probabilities in $\{Y_n\}$ are given by $(P^k)^m = P^{km}$.
\item Therefore, the period of state~$i$ as a state of the chain $\{Y_n\}$ is
\[
   d_Y(i) \;=\; \gcd\!\Bigl\{\, m \ge 1 : \bigl(P^{km}\bigr)_{ii} > 0 \Bigr\}.
\]
We must show that $d_Y(i) = 1$ whenever $d(i) = 1$ in the original chain.
\end{itemize}
\bigskip
\noindent
\textbf{Key idea: Aperiodicity implies eventually-positive returns in all large times.}
A standard characterization of aperiodicity is that for each state $i$, there exists some integer $N$ (possibly depending on~$i$) such that 
\[
  (P^n)_{ii} \;>\; 0 \quad \text{for all } n \ge N.
\]
(Equivalently, the set $\{\,n : (P^n)_{ii} > 0\}$ is \emph{co‐finite}, i.e.\ it contains all sufficiently large~$n$.)
We use this fact to see what happens when we look only at $k$-step transitions, i.e.\ the set 
\[
   \Bigl\{\, m : \bigl(P^{km}\bigr)_{ii} > 0 \Bigr\}.
\]
If $(P^n)_{ii} > 0$ for all $n\ge N$, then in particular $(P^{km})_{ii} > 0$ whenever $km \ge N$.  Hence for all integers
\[
   m \;\ge\; \bigl\lceil N/k \bigr\rceil,
\]
we have $(P^{km})_{ii} > 0.$  Thus 
\[
   \Bigl\{\, m : \bigl(P^{km}\bigr)_{ii} > 0 \Bigr\}
\]
contains \emph{all} sufficiently large integers $m$.
\bigskip
\noindent
\textbf{Period calculation for the chain $\{Y_n\}$.}
For the chain $\{Y_n\}$, the period of $i$ is 
\[
  d_Y(i) 
  \;=\; \gcd\!\Bigl\{\, m \ge 1 : \bigl(P^{km}\bigr)_{ii} > 0 \Bigr\}.
\]
Since this set includes \emph{all} sufficiently large integers $m$, its greatest common divisor must be~$1$.  Indeed, any infinite set of consecutive integers has $\gcd$ equal to~$1$.  Formally:
\begin{itemize}
\item Because $\{X_n\}$ is aperiodic at $i$, there is an $N$ such that $(P^n)_{ii}>0$ for every $n \ge N$.
\item Consequently, for every integer $m \ge \lceil N/k \rceil$, we have 
\[
  (P^{km})_{ii} > 0.
\]
\item Hence $\{ m : (P^{km})_{ii}>0\}$ contains the tail set $\{\lceil N/k\rceil, \lceil N/k\rceil +1, \lceil N/k\rceil+2, \dots\}$ of \emph{all} sufficiently large integers.
\item The greatest common divisor of any infinite set of consecutive integers is~$1$.
\item Therefore $d_Y(i) = 1$.
\end{itemize}
Since $d_Y(i)=1$ for every state $i$, the subsampled chain $\{Y_n\}$ is indeed aperiodic.
}
        
        \item[(d)] (10 points) Suppose that the original chain $\{X_n\}$ is transient. Is $\{Y_n\}$ transient? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}

        
        \item[(e)] (15 points) Suppose that the original chain $\{X_n\}$ is recurrent. Is $\{Y_n\}$ recurrent? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}

        
        \item[(f)] (5 points) Suppose that the original chain $X_n$ is irreducible and that it has period $d$. What is the period of each state $i$ in the new Markov chain $Y_n$ for $k = d$?

           \textcolor{blue}{Since the original chain is irreducible with period~$d$, for each state~$i$,
\[
    (P^d_X)_{ii} \;>\; 0 \quad \text{and} \quad (P^{d-b}_X)_{ii} \;=\; 0, \quad \forall b = 1, 2, \dots, d-1.
\]
Therefore, for any multiple of $d$, $a\in \mathbb{Z}$ such that $a \geq 1$, $$(P^d_X)^a_{ii} > 0$$
As such, all returns to $i$ can occur only at multiples of~$d$ steps.   \\ \\ 
Define the transition matrix for $Y_n$ where $k=d$ as
\[
  \mathbb{P}(Y_{m+1} = j \,\big|\; Y_m = i)
    \;=\; (P^k_X)_{ij}
  \;=\; (P^d_X)_{ij}
\]
When $j=i$, 
\[
  (P^1_Y)_{ii} 
    \;=\; (P^d_X)_{ii}
  \;>\; 0
\]
As such, state $i$ can reach itself in a single step in chain $Y$, forming a self-loop in Y. \\ \\ 
Defining the period of $i$ in $Y$,
\[
  d_Y(i)
  \;=\;
  \gcd\,\bigl\{\, m \;\ge\; 1 : (P^{d\,m})_{ii} > 0 \bigr\}.
\]
Note that $(P^d)_{ii} > 0$, so at $m=1$, $(P^{d\cdot 1})_{ii} = (P^d)_{ii} > 0$. Since the chain is irreducible, raising $P^d$ to a higher power trivially cannot change its positivity:
\[
   (P^{d\,2})_{ii} = \bigl(P^d\bigr)^2_{ii} > 0, 
   \quad
   (P^{d\,3})_{ii} > 0, 
   \;\;\dots
\]
$(P^{dn})_{ii} > 0$ holds for all $n \ge 1$, so the set of possible $m$ is $\{1,2,3,\dots\}$.
Thus,
\[
  \bigl\{\,m : (P^{d\,m})_{ii} > 0 \bigr\}
  \;=\;
  \{1, 2, 3, \dots\},
\]
with a trivial gcd of 1. Note that since the $d$ period was a state property in the original chain, $\{X_n\}$, it holds for all states in the old chain, and thus all states in the new chain. \\ \\ 
As such, the period of each state in the new chain $\{Y_n\}$ is $1$. In other words, the chain $\{Y_n\}$ is aperiodic.
}
    \end{enumerate}

\subsection*{Problem 3} (Asymmetric random walk, 15 points) Consider the \textit{asymmetric} random walk on $\mathbb{Z}$, that is, $X_n = X_{n-1} + Z_n$, where $Z_1, Z_2, \dots$ are iid and $\mathbb{P}(Z_n = +1) = p$ and $\mathbb{P}(Z_n = -1) = 1 - p$, with $p \in [0,1]$ and $p \neq \frac{1}{2}$. Show that the state 0 is a transient state.

    In Lecture 7 we saw/will see that when $p = \frac{1}{2}$ this is not true anymore and the state 0 is recurrent. Can you explain intuitively why this is the case?

    \textit{Hint:} You may want to use Stirling’s formula that $\lim_{n \to \infty} \frac{n!}{(n/e)^n \sqrt{2\pi n}} = 1$.


    \textcolor{blue}{
Starting from \(X_0 = 0\), the random walk is at state \(0\) again at \(t=n\) only when it has taken an equal number of \(+1\) steps as \(-1\) steps. As such, \(n\) must be even. \\ \\ Suppose \(n = 2k\), and \(k\) is the number of \(Z_i\) that are \(+1\),
\[
  \mathbb{P}(X_{2k} = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  \binom{2k}{k}\, p^k\, (1-p)^k
\]
\[
    \text{Note that }\mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0) \;=\; 0
  \ \ \text{if $n$ is odd}
\]
Hence the series of return probabilities at \(0\) is
\[
  \sum_{n=0}^\infty \mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  1 \;+\; \sum_{k=1}^\infty \binom{2k}{k}\, p^k\, (1-p)^k,
\]
accounting for the initial state of 0. \\ Using Stirling's approximation,
\medskip
\noindent
\[
  n! \;\sim\; \Bigl(\tfrac{n}{e}\Bigr)^{n}\sqrt{2\pi n}
  \quad\text{as }n \to \infty,
\]
applying to this case,
\[
  \binom{2k}{k}
  \;=\;
  \frac{(2k)!}{k!\,k!}
  \;\approx\;
  \frac{\sqrt{4\pi k}\,\bigl(\tfrac{2k}{e}\bigr)^{2k}}{\,2\pi k\,\bigl(\tfrac{k}{e}\bigr)^{k}\bigl(\tfrac{k}{e}\bigr)^{k}}
  \;=\;
  \frac{4^k}{\sqrt{\pi k}}
\]
Therefore,
\[
  \binom{2k}{k}\,p^k\,(1-p)^k
  \;\approx\;
  \frac{4^k}{\sqrt{\pi k}} \,\bigl[p(1-p)\bigr]^k
  \;=\;
  \frac{\bigl[4\,p(1-p)\bigr]^k}{\sqrt{\pi k}}.
\]
\medskip
\noindent
If $p \neq \frac{1}{2}$, then \(4\,p(1-p) < 1\) (If $f(x)=x(1-x)$, then $f'(x)=-x+1-x=-2x+1$. Solving for the max when $f'(x)=0, x=\frac{1}{2}$). \\ \\ 
Note, that as \(k \to \infty\), \(\bigl[4\,p(1-p)\bigr]^k\) decays exponentially. Therefore,
\[
  \binom{2k}{k}\,p^k\,(1-p)^k
  \;=\;
  O\!\Bigl(\bigl[4\,p(1-p)\bigr]^k\Bigr)
  \quad
  \text{and}
  \quad
  \sum_{k=1}^{\infty} \binom{2k}{k}\,p^k\,(1-p)^k
  \;<\;\infty.
\]
Thus,
\[
  \sum_{n=0}^\infty \mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  1 \;+\;
  \sum_{k=1}^{\infty}
  \binom{2k}{k}\, p^k\,(1-p)^k
  \;<\;
  \infty.
\]
which defines a transient state. \\ \\ 
\medskip
\noindent
However, when \(p = \frac{1}{2}\),
\[
  \binom{2k}{k}\,\Bigl(\frac12\Bigr)^k\,\Bigl(\frac12\Bigr)^k
  \;\approx\;
    \frac{\bigl[4\cdot 0.5(1-0.5)\bigr]^k}{\sqrt{\pi k}}
  \;=\;
  \frac{1}{\sqrt{\pi k}},
\]
so
\[
  \sum_{k=1}^\infty \frac{1}{\sqrt{k}}
  \;=\;
  \infty.
\]
which defines a recurrent state when $p=\frac12$. }

    \subsection*{Exercise 1.8} Consider a Markov chain on the integers with
\[
P(i, i+1) = 0.4 \text{ and } P(i, i-1) = 0.6 \text{ for } i > 0,
\]
\[
P(i, i+1) = 0.6 \text{ and } P(i, i-1) = 0.4 \text{ for } i < 0,
\]
\[
P(0,1) = P(0,-1) = \frac{1}{2}.
\]

This is a chain with infinitely many states, but it has a sort of probabilistic ``restoring force'' that always pushes back toward 0. Find the stationary distribution.

\textcolor{blue}{
Denote the stationary distribution by $\{\pi_i\}_{i\in\mathbb{Z}}$
\[
\sum_{j \in \mathbb{Z}} \pi_j P(j,i) \;=\; \pi_i
\quad \text{for all } i \in \mathbb{Z},
\]
and $\sum_{i \in \mathbb{Z}} \pi_i = 1$.
As this is a two-sided birth-death chain,
\[
\pi_i \, P(i, i+1) \;=\; \pi_{i+1} \, P(i+1, i).
\]
For $i \ge 1$:
\[
\pi_i \times 0.4 \;=\; \pi_{i+1} \times 0.6
\quad \Longrightarrow \quad 
\frac{\pi_{i+1}}{\pi_i} = \frac{0.4}{0.6} = \frac{2}{3}.
\]
For $i \le -1$:
\[
    \pi_{i-1} \times 0.6 \;=\; \pi_{i} \times 0.4
\quad \Longrightarrow \quad 
\frac{\pi_{i-1}}{\pi_i} = \frac{0.4}{0.6} = \frac{2}{3}.
\]
When $i=0$,
\[
\pi_0 \times 0.5 \;=\; \pi_1 \times 0.6
\quad \Longrightarrow \quad
\frac{\pi_1}{\pi_0} = \frac{0.5}{0.6} = \frac{5}{6}.
\]
\[
\pi_{-1} \times 0.6 = \pi_0 \times 0.5
\quad \Longrightarrow \quad 
\frac{\pi_{-1}}{\pi_{0}} = \frac{0.5}{0.6} = \frac{5}{6},
\]
Hence,
\[
\pi_1 = \frac{5}{6}\,\pi_0, 
\quad
\pi_{-1} = \frac{5}{6}\,\pi_0.
\]
As the probabilities of a jump remain the same, generalizing for all $i\geq1$,
\[
\pi_{i+1} = \frac{2}{3} \pi_{i}
\quad\Longrightarrow\quad 
\pi_i = \left(\frac{2}{3}\right)^{\,i-1} \,\pi_1
\quad \text{for } i \ge 1.
\]
\[
\pi_i 
\;=\; 
\left(\frac{2}{3}\right)^{\,i-1} \cdot \frac{5}{6}\,\pi_0
\quad \forall i \ge 1.
\]
Generalizing for all $i\leq-1$,
\[
    \pi_{i-1} = \frac{2}{3} \pi_{i}
\quad\Longrightarrow\quad
\pi_{i} = \frac{2}{3}^{-i-1}\,\pi_{-1}
\quad \forall i\leq -1,
\]
\[
    \pi_{i} 
\;=\; 
\left(\frac{2}{3}\right)^{\,-i-1} \cdot \frac{5}{6}\,\pi_0
\quad \forall i \leq -1.
\]
Combining the two cases,
\[
\pi_i 
\;=\;
\frac{5}{6}\,\left(\frac{2}{3}\right)^{\,|i|-1}\,\pi_0, \quad \forall i \neq 0.
\]
Solving for $\pi_0$, first recall that,
\[
\sum_{i=-\infty}^{\infty} \pi_i \;=\; 1.
\]
Hence,
\[
\pi_0 
\;+\;
\sum_{i\neq 0} \frac{5}{6} \,\biggl(\tfrac{2}{3}\biggr)^{|i|-1}\,\pi_0
\;=\; 1.
\]
\[
\pi_0 
\biggl[
1 
\;+\; 
\frac{5}{6}\sum_{i\neq 0}\bigl(\tfrac{2}{3}\bigr)^{|i|-1}
\biggr]
\;=\; 1.
\]
Exploiting the symmetry of the chain,
\[
\sum_{i\neq 0}\bigl(\tfrac{2}{3}\bigr)^{|i|-1} 
\;=\;
2 \sum_{j=1}^{\infty} \bigl(\tfrac{2}{3}\bigr)^{j-1}
\;=\;
2 \sum_{k=0}^{\infty} \bigl(\tfrac{2}{3}\bigr)^{k}
\;=\;
2 \cdot \frac{1}{1 - \tfrac{2}{3}}
\;=\;
2 \cdot 3
\;=\;
6.
\]
Thus
\[
\pi_0 \Bigl[\,1 + \frac56 \cdot 6\,\Bigr] 
\;=\;
6\,\pi_0
\;=\;
1 
\quad\Longrightarrow\quad
\pi_0 
\;=\; 
\frac{1}{6}.
\]
Therefore,
\[
\pi_i
=
\begin{cases}
\displaystyle \frac{1}{6},
& i=0\\[6pt]
\displaystyle \frac{5}{36}\,\bigl(\tfrac{2}{3}\bigr)^{|i|-1}
& i \neq 0
\end{cases}
\]
}


\subsection*{Exercise 1.16} Show that if an irreducible Markov chain has a state $i$ such that $P(i, i) > 0$, then the chain
is aperiodic. Also show by example that this sufficient condition is not necessary.

\textcolor{blue}{
Let $\{X_n\}$ be an irreducible Markov chain on a countable state space $S$. Suppose there is a state $i \in S$ such that
\[
    P(i,i) > 0.
\]
The period of state $i$ is defined as
\[
    d(i) \;=\; \gcd \{ n \ge 1 : P^n(i,i) > 0 \},
\]
Since $P(i,i) = P^1(i,i)> 0$, there is a positive probability of returning to $i$ in exactly 1 step. As such, $1 \in \{n: P^n(i,i) > 0\}$, so any common divisor of all $n$ must trivially divide 1. \\ \\ Therefore,
\[
    d(i) \;=\; \gcd \{ n \ge 1 : P^n(i,i) > 0 \} \;=\; 1.
\]
Thus, $i$ is an aperiodic state. \\ \\ 
By irreducibility, for any other state $j \in S$, $\exists m,k \in \mathbb{Z}$ such that $ m,k\ge 1$, $P^m(j,i) > 0$, and $P^k(i,j) > 0$. Therefore as proven in lecture, for any $n \ge 1$,
\[
    P^{m+n+k}(j,j) 
    \;\ge\; P^m(j,i) \, P^n(i,i) \, P^k(i,j).
\]
Since $P^n(i,i) > 0$ for all $n \ge 1$, for arbitrarily many $n$, the probability $P^{m+n+k}(j,j)$ is strictly positive. As such,
\[
    d(j) \;=\; \gcd\{ n \ge 1 : P^n(j,j) > 0 \} \;=\; 1.
\]
Thus, every state in an irreducible chain with a self-loop, i.e. $P(i,i) > 0$, is aperiodic. \\ \\ 
To show that this sufficient condition is not necessary, consider a chain on three states $\{1,2,3\}$ with transition matrix:
\[
    P(1,1)=0, \quad P(1,2)=1, \quad P(1,3)=0, 
\]
\[
    P(2,1)=\tfrac{1}{2}, \quad P(2,2)=0, \quad P(2,3)=\tfrac{1}{2},
\]
\[
    P(3,1)=\tfrac{1}{2}, \quad P(3,2)=\tfrac{1}{2}, \quad P(3,3)=0.
\]
Note that the chain is irreducible, but does not contain any self-loops, i.e. $P(i,i)=0$ for $i=1,2,3$. \\ \\ 
\[
    P^2(1,1) = P(1,2)P(2,1) = (1)\left(\tfrac{1}{2}\right) = \tfrac{1}{2} > 0,
\]
\[
    P^3(1,1) = P(1,2)P(2,3)P(3,1) = 1 \cdot \tfrac{1}{2} \cdot \tfrac{1}{2}
    = \tfrac{1}{4} > 0.
\]
Therefore, state $1$ can return to itself in both $2$ steps and $3$ steps, which comprises a subset of the set of all possible return times back to state 1. The gcd of $2$ and $3$ is $1$, or a period of $1$. 
Note that $P^2(2,2)>0$, $P^2(3,3)>0$, and $P^3(2,2)>0$, $P^3(3,3)>0$, so every state also has period $1$, making the entire chain aperiodic.
Thus, $P(i,i) > 0$ for some $i$ is not a necessary condition for a chain to be aperiodic.
}


\end{document}

