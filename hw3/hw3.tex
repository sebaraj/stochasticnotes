\documentclass{article}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{parskip}


\usepackage[a4paper, margin=1in]{geometry}

\title{S\&DS 351: Stochastic Processes - Homework 3}
\author{Bryan SebaRaj \\[0.8em] Professor Ilias Zadik}
\date{February 7, 2025}

\begin{document}

\maketitle

\subsection*{Problem 1} (10 points) Is it possible for a transient state to be periodic? If so, construct an example of such a Markov chain; otherwise, give a mathematical proof why not.

\textcolor{blue}{Note: I (fortunately) solved this after proving problem 3, so for a more thorough proof on how this example is transient, please see Problem 3. \\ \\ 
Yes, it is possible for a transient state to be periodic. Consider a 1-dimensional asymmetric random walk on $\mathbb{Z}$:
\[
   X_{n} \;=\; X_{n-1} \;+\; Z_n,
   \quad\text{where}\quad
   \mathbb{P}(Z_n = +1) \;=\; p
   \quad\text{and}\quad
   \mathbb{P}(Z_n = -1) \;=\; 1 - p,
\]
for some $p \in (0,1)$ with $p \neq \tfrac{1}{2}$. Starting at state 0, state 0 is transient (see Problem 3). \\ \\ 
% We claim that in this Markov chain:
% \begin{enumerate}
%   \item \emph{State 0 is transient} whenever $p \neq \tfrac{1}{2}.$
%   \item \emph{State 0 has period 2}, regardless of $p$ (as long as $p>0$ and $1-p>0$).
% \end{enumerate}
\smallskip
\noindent
Define the period as $d_i = \text{gcd}\{n:P^n(i,i)>0\}$, where $P$ is the transition matrix. \\
In the random walk, the walk must trivially take as many $+1$ steps as $-1$ steps to reach the initial state. Thus one can only return to state $x$ starting from $x$ in an even number of steps. Hence for each integer $x$, 
\[
  (P^n)(x,x) \;>\;0 
  \quad\Longrightarrow\quad 
  n \ \text{is even}.
\]
\[
  (P^n)(x,x) \;=\;0 
  \quad\Longrightarrow\quad 
  n \ \text{is odd}.
\]
Therefore, the greatest common divisor of all such $n$ is $2$, and every state $x\in\mathbb{Z}$ has period~$2$.
}
   
\subsection*{Problem 2} Let $X_0, X_1, \dots$ be a Markov chain with transition matrix $P$. Let $k \geq 1$ be an integer.
    \begin{enumerate}
        \item (5 points) Prove that $Y_n = X_{kn}$ is also a Markov chain. Find its transition matrix.

            \textcolor{blue}{}

        
        \item (10 points) Suppose that the original chain $\{X_n\}$ is irreducible. Is $\{Y_n\}$ irreducible? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}

        
        \item (10 points) Suppose that the original chain $\{X_n\}$ is aperiodic. Is $\{Y_n\}$ aperiodic? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}
        
        \item (10 points) Suppose that the original chain $\{X_n\}$ is transient. Is $\{Y_n\}$ transient? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}

        
        \item (15 points) Suppose that the original chain $\{X_n\}$ is recurrent. Is $\{Y_n\}$ recurrent? If so, prove it; if not, provide a counterexample.

            \textcolor{blue}{}

        
        \item (5 points) Suppose that the original chain $X_n$ is irreducible and that it has period $d$. What is the period of each state $i$ in the new Markov chain $Y_n$ for $k = d$?

           \textcolor{blue}{}

    \end{enumerate}

\subsection*{Problem 3} (Asymmetric random walk, 15 points) Consider the \textit{asymmetric} random walk on $\mathbb{Z}$, that is, $X_n = X_{n-1} + Z_n$, where $Z_1, Z_2, \dots$ are iid and $\mathbb{P}(Z_n = +1) = p$ and $\mathbb{P}(Z_n = -1) = 1 - p$, with $p \in [0,1]$ and $p \neq \frac{1}{2}$. Show that the state 0 is a transient state.

    In Lecture 7 we saw/will see that when $p = \frac{1}{2}$ this is not true anymore and the state 0 is recurrent. Can you explain intuitively why this is the case?

    \textit{Hint:} You may want to use Stirlingâ€™s formula that $\lim_{n \to \infty} \frac{n!}{(n/e)^n \sqrt{2\pi n}} = 1$.


    \textcolor{blue}{
Starting from \(X_0 = 0\), the random walk is at state \(0\) again at \(t=n\) only when it has taken an equal number of \(+1\) steps as \(-1\) steps. As such, \(n\) must be even. \\ \\ Suppose \(n = 2k\), and \(k\) is the number of \(Z_i\) that are \(+1\),
\[
  \mathbb{P}(X_{2k} = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  \binom{2k}{k}\, p^k\, (1-p)^k
\]
\[
    \text{Note that }\mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0) \;=\; 0
  \ \ \text{if $n$ is odd}
\]
Hence the series of return probabilities at \(0\) is
\[
  \sum_{n=0}^\infty \mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  1 \;+\; \sum_{k=1}^\infty \binom{2k}{k}\, p^k\, (1-p)^k,
\]
accounting for the initial state of 0. \\ Using Stirling's approximation,
\medskip
\noindent
\[
  n! \;\sim\; \Bigl(\tfrac{n}{e}\Bigr)^{n}\sqrt{2\pi n}
  \quad\text{as }n \to \infty,
\]
applying to this case,
\[
  \binom{2k}{k}
  \;=\;
  \frac{(2k)!}{k!\,k!}
  \;\approx\;
  \frac{\sqrt{4\pi k}\,\bigl(\tfrac{2k}{e}\bigr)^{2k}}{\,2\pi k\,\bigl(\tfrac{k}{e}\bigr)^{k}\bigl(\tfrac{k}{e}\bigr)^{k}}
  \;=\;
  \frac{4^k}{\sqrt{\pi k}}
\]
Therefore,
\[
  \binom{2k}{k}\,p^k\,(1-p)^k
  \;\approx\;
  \frac{4^k}{\sqrt{\pi k}} \,\bigl[p(1-p)\bigr]^k
  \;=\;
  \frac{\bigl[4\,p(1-p)\bigr]^k}{\sqrt{\pi k}}.
\]
\medskip
\noindent
If $p \neq \frac{1}{2}$, then \(4\,p(1-p) < 1\) (If $f(x)=x(1-x)$, then $f'(x)=-x+1-x=-2x+1$. Solving for the max when $f'(x)=0, x=\frac{1}{2}$). \\ \\ 
Note, that as \(k \to \infty\), \(\bigl[4\,p(1-p)\bigr]^k\) decays exponentially. Therefore,
\[
  \binom{2k}{k}\,p^k\,(1-p)^k
  \;=\;
  O\!\Bigl(\bigl[4\,p(1-p)\bigr]^k\Bigr)
  \quad
  \text{and}
  \quad
  \sum_{k=1}^{\infty} \binom{2k}{k}\,p^k\,(1-p)^k
  \;<\;\infty.
\]
Thus,
\[
  \sum_{n=0}^\infty \mathbb{P}(X_n = 0 \,\big\vert\, X_0 = 0)
  \;=\;
  1 \;+\;
  \sum_{k=1}^{\infty}
  \binom{2k}{k}\, p^k\,(1-p)^k
  \;<\;
  \infty.
\]
which defines a transient state. \\ \\ 
\medskip
\noindent
However, when \(p = \frac{1}{2}\),
\[
  \binom{2k}{k}\,\Bigl(\frac12\Bigr)^k\,\Bigl(\frac12\Bigr)^k
  \;\approx\;
    \frac{\bigl[4\cdot 0.5(1-0.5)\bigr]^k}{\sqrt{\pi k}}
  \;=\;
  \frac{1}{\sqrt{\pi k}},
\]
so
\[
  \sum_{k=1}^\infty \frac{1}{\sqrt{k}}
  \;=\;
  \infty.
\]
which defines a recurrent state when $p=\frac12$. }

    \subsection*{Exercise 1.8} Consider a Markov chain on the integers with
\[
P(i, i+1) = 0.4 \text{ and } P(i, i-1) = 0.6 \text{ for } i > 0,
\]
\[
P(i, i+1) = 0.6 \text{ and } P(i, i-1) = 0.4 \text{ for } i < 0,
\]
\[
P(0,1) = P(0,-1) = \frac{1}{2}.
\]

This is a chain with infinitely many states, but it has a sort of probabilistic ``restoring force'' that always pushes back toward 0. Find the stationary distribution.

\textcolor{blue}{}


\subsection*{Exercise 1.10} On page \textbf{13} we argued that a limiting distribution must be stationary. This argument was clear in the case of a finite state space. For you fans of mathematical analysis, what happens in the case of a countably infinite state space? Can you still make the limiting argument work?

\textcolor{blue}{}


\end{document}

